<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset='utf-8'>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <!--<link rel="stylesheet" type="text/css" href="/assets/css/print.css" media="print">-->
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Aplicando KNN no banco de dados Iris | Lab 208</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="Aplicando KNN no banco de dados Iris" />
<meta name="author" content="Tony" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Agora que já conhecemos o funcionamento do KNN iremos investigar os dados do Iris, aplicar o algoritmo e testar os resultados. Tudo isso será feito utilizando a biblioteca pandas para ler os dados e sklearn para aplicar o modelo." />
<meta property="og:description" content="Agora que já conhecemos o funcionamento do KNN iremos investigar os dados do Iris, aplicar o algoritmo e testar os resultados. Tudo isso será feito utilizando a biblioteca pandas para ler os dados e sklearn para aplicar o modelo." />
<link rel="canonical" href="http://localhost:4000/2020/05/08/knn2.html" />
<meta property="og:url" content="http://localhost:4000/2020/05/08/knn2.html" />
<meta property="og:site_name" content="Lab 208" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-05-08T00:00:00-03:00" />
<script type="application/ld+json">
{"headline":"Aplicando KNN no banco de dados Iris","dateModified":"2020-05-08T00:00:00-03:00","datePublished":"2020-05-08T00:00:00-03:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2020/05/08/knn2.html"},"url":"http://localhost:4000/2020/05/08/knn2.html","author":{"@type":"Person","name":"Tony"},"description":"Agora que já conhecemos o funcionamento do KNN iremos investigar os dados do Iris, aplicar o algoritmo e testar os resultados. Tudo isso será feito utilizando a biblioteca pandas para ler os dados e sklearn para aplicar o modelo.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

  <body>
    <div id="container">
      <div class="inner">
        <header>
          <h1>Lab|208</h1>
          <h2>Clusterizando conhecimento.</h2>
        </header>
        <section id="downloads" class="clearfix">
	  <nav>
  	    
    	      <a href="/" class="button" >
              <span>Home</span>
              </a>
            
    	      <a href="/about.html" class="button" >
              <span>Sobre</span>
              </a>
            
    	      <a href="/blog.html" class="button" >
              <span>Blog</span>
              </a>
            
    	      <a href="/authors.html" class="button" >
              <span>Membros</span>
              </a>
            
          </nav>
        </section>
        <hr>
        <section id="main_content">
          <h1>Aplicando KNN no banco de dados Iris</h1>
<p>
  08 May 2020

  
  
    
       
         
         - <a href="/authors/anthony.html">Anthony João Bet</a>
       
    
  
</p>
<p>Agora que já conhecemos o funcionamento do KNN iremos investigar os dados do Iris, aplicar o algoritmo e testar os resultados. Tudo isso será feito
utilizando a biblioteca <a href="https://pandas.pydata.org/">pandas</a> para ler os dados e <a href="https://scikit-learn.org/stable/">sklearn</a> para aplicar o modelo.
<!--more--></p>
<h2 id="baixando-os-dados">Baixando os dados</h2>

<p>Você pode encontra os dados para o projeto no <a href="https://archive.ics.uci.edu/ml/index.php">UCI Machine Learning Repository</a> ou diretamente pelo
<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/iris/">link</a>, o nome do arquivo é <code class="highlighter-rouge">iris.data</code>.
O UCI foi criado em 1987 e hoje agrega mais de 490 datasets para diversos tipos de projetos.</p>

<p>Descrição dos dados encontrada no UCI:</p>

<ul>
  <li>sepal length in cm</li>
  <li>sepal width in cm</li>
  <li>petal length in cm</li>
  <li>petal width in cm</li>
  <li>class:
    <ul>
      <li>Iris Setosa</li>
      <li>Iris Versicolour</li>
      <li>Iris Virginica</li>
    </ul>
  </li>
</ul>

<p>Se abrirmos o arquivo de dados é isso que encontraremos:</p>

<p align="center">
 <img src="/assets/images/anthony/knn2_iris_raw.png" alt="dados iris" width="620" />
</p>

<p>As quatro primeiras colunas representam as características de uma planta e a última coluna, sua espécie. Então a pergunta que queremos responder é:
Dado um <strong>novo</strong> conjunto de características <code class="highlighter-rouge">['sepal_length','sepal_width','petal_length','petal_width']</code>, qual é a espécie dessa planta?</p>

<h2 id="bora-pro-codigo">Bora pro codigo</h2>

<p>Para ler o dataset nós iremos utilizar a biblioteca pandas;</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
 
<span class="k">def</span> <span class="nf">carregar_dados</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
   <span class="s">"""Função para ler os dados"""</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s">'sepal_length'</span><span class="p">,</span><span class="s">'sepal_width'</span><span class="p">,</span><span class="s">'petal_length'</span><span class="p">,</span><span class="s">'petal_width'</span><span class="p">,</span><span class="s">'class'</span><span class="p">])</span>
   <span class="k">return</span> <span class="n">df</span>
 
<span class="n">df</span> <span class="o">=</span> <span class="n">carregar_dados</span><span class="p">(</span><span class="s">'iris.data'</span><span class="p">)</span>
</code></pre></div></div>

<p>Em geral, em problemas reais muitos dados podem estar faltando no datset, isso pode acontecer por diversos motivos como a falha em algum sensor, erro humano,
aleatoriedade no sistema e por aí vai. Os dados que estamos utilizando não possuem nem um erro desse tipo, então não iremos nos preocupar com isso agora.
Tratar os dados antes de aplicar qualquer modelos é uma parte essencial do processo, mas iremos falar sobre isso quando chegar a hora.</p>

<p>No UCI podemos encontrar informações estatísticas sobre os dados:</p>

<div class="language-s highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Summary</span><span class="w"> </span><span class="n">Statistics</span><span class="o">:</span><span class="w">
           </span><span class="n">Min</span><span class="w">  </span><span class="n">Max</span><span class="w">   </span><span class="n">Mean</span><span class="w">    </span><span class="n">SD</span><span class="w">   </span><span class="n">Class</span><span class="w"> </span><span class="n">Correlation</span><span class="w">
   </span><span class="n">sepal</span><span class="w"> </span><span class="n">length</span><span class="o">:</span><span class="w"> </span><span class="m">4.3</span><span class="w">  </span><span class="m">7.9</span><span class="w">   </span><span class="m">5.84</span><span class="w">  </span><span class="m">0.83</span><span class="w">    </span><span class="m">0.7826</span><span class="w">  
   </span><span class="n">sepal</span><span class="w"> </span><span class="n">width</span><span class="o">:</span><span class="w">  </span><span class="m">2.0</span><span class="w">  </span><span class="m">4.4</span><span class="w">   </span><span class="m">3.05</span><span class="w">  </span><span class="m">0.43</span><span class="w">   </span><span class="m">-0.4194</span><span class="w">
   </span><span class="n">petal</span><span class="w"> </span><span class="n">length</span><span class="o">:</span><span class="w"> </span><span class="m">1.0</span><span class="w">  </span><span class="m">6.9</span><span class="w">   </span><span class="m">3.76</span><span class="w">  </span><span class="m">1.76</span><span class="w">    </span><span class="m">0.9490</span><span class="w">  </span><span class="p">(</span><span class="n">high</span><span class="o">!</span><span class="p">)</span><span class="w">
   </span><span class="n">petal</span><span class="w"> </span><span class="n">width</span><span class="o">:</span><span class="w">  </span><span class="m">0.1</span><span class="w">  </span><span class="m">2.5</span><span class="w">   </span><span class="m">1.20</span><span class="w">  </span><span class="m">0.76</span><span class="w">    </span><span class="m">0.9565</span><span class="w">  </span><span class="p">(</span><span class="n">high</span><span class="o">!</span><span class="p">)</span><span class="w">
 
 
</span><span class="n">Distribuição</span><span class="w"> </span><span class="n">das</span><span class="w"> </span><span class="n">classes</span><span class="o">:</span><span class="w"> </span><span class="m">33.3</span><span class="o">%</span><span class="w"> </span><span class="n">para</span><span class="w"> </span><span class="n">cada</span><span class="w"> </span><span class="n">uma</span><span class="w"> </span><span class="n">das</span><span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="n">classes.</span><span class="w">
</span></code></pre></div></div>

<p>Isso nos diz que o tamanho das pétalas está altamente correlacionado com sua classe e que número de amostras está igualmente dividido entre o total dos
dados, isso é muito importante, pois significa, de forma grosseira, que cada classe possui a mesma importância.</p>

<p>Nossos dados estão todos em um dataframe, precisamos separá-los em dois grupos X e Y, onde X será um novo conjunto apenas com as características (input)
e Y um conjunto com as classes:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'sepal_length'</span><span class="p">,</span><span class="s">'sepal_width'</span><span class="p">,</span><span class="s">'petal_length'</span><span class="p">,</span><span class="s">'petal_width'</span><span class="p">]]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'class'</span><span class="p">]</span>
</code></pre></div></div>

<p>Outra coisa que precisamos mudar é a forma como identificamos nossas classes, no momento cada classe é identificada por uma string, e queremos que
cada classe seja identificada por um número inteiro. Essa transformação pode ser feita facilmente com a biblioteca sklearn, dessa forma:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
 
<span class="n">encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">encoder</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
</code></pre></div></div>

<p>Se printarmos novamente, é isso que temos:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-s highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">➜</span><span class="w">  </span><span class="n">iris</span><span class="w"> </span><span class="n">python3</span><span class="w"> </span><span class="n">classification.py</span><span class="w">
</span><span class="p">[</span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w">
</span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w">
</span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="w">
</span><span class="m">2</span><span class="w"> </span><span class="m">2</span><span class="p">]</span><span class="w">
</span></code></pre></div></div>

<p>Meio feio, mas é isso mesmo que queremos.</p>

<p>Agora precisamos preparar os dados para o treinamento. Para fazer isso os dados devem embaralhados e separados em grupo de treino
e grupo de deste. O grupo de treino será utilizado para treinar o algoritmo, e o grupo de teste para validar este treino, ou seja, testar o algoritmo em
dados que ele nunca viu, para garantir sua eficácia.</p>

<p>Novamente iremos utilizar a biblioteca sklearn. Existem dois parâmetros que precisamos entender nessa função, o parâmetro <code class="highlighter-rouge">test_size</code> regula a porcentagem
do dataset que será separado como teste e com <code class="highlighter-rouge">shuffle</code> escolhemos se queremos que os dados sejam embaralhados antes de serem separados, se olharmos para a
figura anterior veremos que as classes estão dispostas em sequência, sendo assim precisamos embaralhar nossos dados;</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
 
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span> <span class="n">X</span><span class="p">,</span>
                                                     <span class="n">Y</span><span class="p">,</span>
                                                     <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span>
                                                     <span class="n">shuffle</span> <span class="o">=</span> <span class="bp">True</span>
                                                    <span class="p">)</span>
</code></pre></div></div>

<p>Tudo pronto! Agora podemos finalmente aplicar o algoritmo nos dados;</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
 
<span class="n">modelo</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                              <span class="n">algorithm</span> <span class="o">=</span> <span class="s">'brute'</span>
                              <span class="p">)</span>
 
<span class="n">modelo</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
</code></pre></div></div>

<p>Não é necessário informar que estamos utilizando distância euclidiana, isso já é escolhido por padrão.
O parâmetro <code class="highlighter-rouge">n_neighbors</code> define quantos vizinhos vamos utilizar para contagem, devemos escolher um número que não gere empates e
<code class="highlighter-rouge">algorithm = 'brute'</code> significa que o modelo irá calcular a distância entre o novo ponto e todos os outros pontos dos dados de treino, este é o jeito mais
pedestre e menos eficiente, mas como nosso banco de dados é pequeno isso não será um problema.</p>

<p>É isso aí, após aplicar o função fit nos dados o modelo estará “treinado”, agora podemos utilizar o modelo para fazer predições. Vamos escolher um ponto do
conjunto de teste e ver qual a classificação:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#novo ponto será o último ponto em X_test
</span><span class="n">novo_ponto</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="n">values</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s">f'Novo ponto: </span><span class="si">{</span><span class="n">novo_ponto</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
 
<span class="n">prediction</span> <span class="o">=</span> <span class="n">modelo</span><span class="p">.</span><span class="n">predict</span><span class="p">([</span><span class="n">novo_ponto</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">f'Predição: </span><span class="si">{</span><span class="n">prediction</span><span class="si">}</span><span class="s">, Classe correta: </span><span class="si">{</span><span class="n">Y_test</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>
<p>Que nos retorna:</p>

<div class="language-s highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">➜</span><span class="w">  </span><span class="n">iris</span><span class="w"> </span><span class="n">python3</span><span class="w"> </span><span class="n">classification.py</span><span class="w">

</span><span class="n">Novo</span><span class="w"> </span><span class="n">ponto</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="m">6.3</span><span class="w"> </span><span class="m">3.3</span><span class="w"> </span><span class="m">4.7</span><span class="w"> </span><span class="m">1.6</span><span class="p">]</span><span class="w">
 
</span><span class="n">Predição</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="m">1</span><span class="p">],</span><span class="w"> </span><span class="n">Classe</span><span class="w"> </span><span class="n">correta</span><span class="o">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span></code></pre></div></div>

<p>Um ponto é muito pouco para sabermos se a classificação é boa ou não, a acuracia do modelo
é dada pela razão entre o número de acertos e o número de tentativas.</p>

<p>Podemos fazer o seguinte, vamos comparar o conjunto de predição com o conjunto
de teste (<code class="highlighter-rouge">prediction == Y_test</code>) , isso irá comparar os dois arrays entrada por entrada, em ordem, e irá retornar um array de verdadeiro ou falso 
<br />(<code class="highlighter-rouge">[True, True, False, True, ... , False]</code>), podemos
então somar esse array, isso nos dará o número de acertos já que
verdadeiros são representados por 1 e falsos por 0, depois basta dividir
isso pelo tamanho da conjunto.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prediction</span> <span class="o">=</span> <span class="n">modelo</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">acertos</span> <span class="o">=</span> <span class="p">(</span><span class="n">prediction</span> <span class="o">==</span> <span class="n">Y_test</span><span class="p">).</span><span class="nb">sum</span><span class="p">()</span>
<span class="n">erros</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="o">-</span> <span class="n">acertos</span>
<span class="n">acuracia</span> <span class="o">=</span> <span class="n">acertos</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
 
<span class="k">print</span><span class="p">(</span><span class="s">f'Acuracia: </span><span class="si">{</span><span class="n">acuracia</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">f'Acertos:  </span><span class="si">{</span><span class="n">acertos</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">f'Erros:    </span><span class="si">{</span><span class="n">erros</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<p>Ao rodarmos o programa, esse é o resultado que obtemos:</p>

<div class="language-s highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">➜</span><span class="w">  </span><span class="n">iris</span><span class="w"> </span><span class="n">python3</span><span class="w"> </span><span class="n">classification.py</span><span class="w">

</span><span class="n">Acuracia</span><span class="o">:</span><span class="w"> </span><span class="m">0.9555555555555556</span><span class="w">
</span><span class="n">Acertos</span><span class="o">:</span><span class="w">  </span><span class="m">43</span><span class="w">
</span><span class="n">Erros</span><span class="o">:</span><span class="w">    </span><span class="m">2</span><span class="w">
</span></code></pre></div></div>

<p>Note a que a cada vez que o programa for executado, o resultado será um pouco diferente, isso ocorre porque estamos escolhendo aleatoriamente os grupos de treino e teste a cada vez que rodamos o programa, para obtermos uma estimativa mais precisa da acurácia seria necessário fazer uma média, rodando varias vezes o programa. Depois de fazer isso você pode variar o número de K-vizinhos e observar como a acurácia reage a isso.</p>

<p>Eu não me preocupei em explicar como funciona cada biblioteca e não mostrei todas as suas ferramenta, mas deixei linkado as paginas com as documentações. É super difícil entender o funcionamento de cada função dessa na primeira vez, o que eu mostrei aqui tem o intúito se ser um primeiro passo, então não deixe de ler a documentação e aplicar em outros problemas.</p>

<p>Obrigado pela leitura e até a próxima.</p>

<h1 id="fim">FIM!</h1>



        </section>
      </div>
    </div>

    
  </body>
</html>
